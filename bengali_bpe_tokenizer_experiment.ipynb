{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1FtjWAOj1Ahmh7VGl8w3jgwYgT2DFe7_4",
      "authorship_tag": "ABX9TyOv8j7oylZrQlmhJJmFX7IL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayanbanerjee32/TASI_ERAv2_S20/blob/main/bengali_bpe_tokenizer_experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ku_wMD5WqHku",
        "outputId": "10863e22-796b-4a01-8eff-18f407b794b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# copy the begali corpus file\n",
        "!cp /content/drive/MyDrive/ERAv2_datasets/bengali_corpus/ben.txt ."
      ],
      "metadata": {
        "id": "HPULPv13qOLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "j7b-9-753MZN",
        "outputId": "c172989f-1459-493b-a36f-a07cf382c393"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'্য সবাই যা করতে চায় তা করতে চায়নি।\\nএকা থাকার একটা অসুবিধে হোলো যে কথা বলার মতো কেউ থাকে না।\\nআপনার সমস্ত অর্থ দিয়ে আপনি যা চান তা কিনতে সক্ষম হওয়া উচিত।\\nবাইরে এতই গরম যে আমি পুরোদিন আমার শীততাপ নিয়ন্ত্রিত বাড়িতে থাকতে চাই।\\nসকালে সূর্য পূর্ব দিকে ওঠে এবং সন্ধ্যায় পশ্চিমে অস্ত যায়।\\nআমি শুনলাম যে তাঁরা পার্ক স্ট্রিটের একটা বাড়ির ভিতের মধ্যে থেকে একটা কঙ্কাল পেয়েছেন।\\nটম যখন শুনলো যে মেরি আরে জন বিয়ে করেছে তখন তাকে দেখে বেশ অবাক মনে হয়েছিলো।\\nআমার মনে হয় টম যে সোনা পেয়েছে সেটা তার কাছে রাখতে দেওয়া হবে এমন সম্ভাবনা খুব কম।\\nটম মেরিকে বললো যে ও নিজেকে হত্যা করতে চলেছিলো, কিন্ত তা করার মতো সাহস ছিলো না।\\nটমের সঙ্গে কাজ করা খুব বিরক্তিকর কারণ ও কখনই মেনে নেয় না যে ও ভুল করেছে।\\nআমি ভেবেছিলাম এটা করা সহজ হবে, কিন্তু আমরা সারাদিন ধরে কাজ করেছি আর এখনো শেষ করে উঠতে পারিনি।\\nআমি ভেবেছিলাম এটা করা সহজ হবে, কিন্তু আমরা সারাদিন ধরে কাজ করেছি আর এখনো শেষ করে উঠতে পারিনি।\\nবছরের বারোটা মাস হলো জানুয়ারি, ফেব্রুয়ারি, মার্চ, এপ্রিল, মে, জুন জুলাই, আগস্ট, সেপ্টেম্বর, অক্টোবর, নভেম্বর আর ডিসেম্বর।'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "with open('ben.txt', 'r') as _f:\n",
        "    # raw_text = _f.readlines()\n",
        "    raw_lines = [line.split('\\t')[1] for line in _f]\n",
        "    ben_text = '\\n'.join(raw_lines)\n",
        "\n",
        "ben_text[-1000:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = ben_text.encode(\"utf-8\") # raw bytes\n",
        "tokens = list(map(int, tokens)) # convert to a list of integers in range 0..255 for convenience\n",
        "print('---')\n",
        "print(ben_text[:100])\n",
        "print(\"length:\", len(ben_text))\n",
        "print('---')\n",
        "print(tokens[:100])\n",
        "print(\"length:\", len(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-oo9R4Q3unH",
        "outputId": "a7d00fca-0337-489e-a8c9-9061218461cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "যাও।\n",
            "যান।\n",
            "যা।\n",
            "পালাও!\n",
            "পালান!\n",
            "কে?\n",
            "বাহ!\n",
            "আগুন!\n",
            "বাঁচাও!\n",
            "বাঁচান!\n",
            "ঝাঁপ দাও।\n",
            "থামুন!\n",
            "থামো!\n",
            "থাম!\n",
            "নমস্কার!\n",
            "হ্যা\n",
            "length: 169112\n",
            "---\n",
            "[224, 166, 175, 224, 166, 190, 224, 166, 147, 224, 165, 164, 10, 224, 166, 175, 224, 166, 190, 224, 166, 168, 224, 165, 164, 10, 224, 166, 175, 224, 166, 190, 224, 165, 164, 10, 224, 166, 170, 224, 166, 190, 224, 166, 178, 224, 166, 190, 224, 166, 147, 33, 10, 224, 166, 170, 224, 166, 190, 224, 166, 178, 224, 166, 190, 224, 166, 168, 33, 10, 224, 166, 149, 224, 167, 135, 63, 10, 224, 166, 172, 224, 166, 190, 224, 166, 185, 33, 10, 224, 166, 134, 224, 166, 151, 224, 167, 129, 224, 166]\n",
            "length: 443302\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ord('য'), chr(2479), ord(\"!\"), chr(33)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcuD3s878Azi",
        "outputId": "ed23b99e-0617-4196-ce03-396d5a92c559"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2479, 'য', 33, '!')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_stats(ids):\n",
        "    counts = {}\n",
        "    for pair in zip(ids, ids[1:]): # Pythonic way to iterate consecutive elements\n",
        "        counts[pair] = counts.get(pair, 0) + 1\n",
        "    return counts\n",
        "\n",
        "stats = get_stats(tokens)"
      ],
      "metadata": {
        "id": "aowAwkKG5iYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_pair = max(stats, key=stats.get)\n",
        "top_pair, chr(top_pair[0]), chr(top_pair[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJFOQrfF5qay",
        "outputId": "f74078e8-35fa-48f8-b81a-06a2e7397906"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((224, 166), 'à', '¦')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = ben_text.encode(\"utf-8\") # raw bytes\n",
        "tokens = list(map(int, tokens)) # convert to a list of integers in range 0..255 for convenience\n",
        "len(tokens), len(set(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQKXH37p5rqX",
        "outputId": "a9a20809-81cf-4534-b081-c692ba016c8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(443302, 74)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_stats(ids):\n",
        "    counts = {}\n",
        "    for pair in zip(ids, ids[1:]):\n",
        "        counts[pair] = counts.get(pair, 0) + 1\n",
        "    return counts\n",
        "\n",
        "def merge(ids, pair, idx):\n",
        "  newids = []\n",
        "  i = 0\n",
        "  while i < len(ids):\n",
        "    if i < len(ids) - 1 and ids[i] == pair[0] and ids[i+1] == pair[1]:\n",
        "      newids.append(idx)\n",
        "      i += 2\n",
        "    else:\n",
        "      newids.append(ids[i])\n",
        "      i += 1\n",
        "  return newids\n",
        "\n",
        "# ---\n",
        "vocab_size = 1001 # the desired final vocabulary size\n",
        "num_merges = vocab_size - len(set(tokens))\n",
        "ids = list(tokens) # copy so we don't destroy the original list\n",
        "\n",
        "merges = {} # (int, int) -> int\n",
        "for i in range(num_merges):\n",
        "  stats = get_stats(ids)\n",
        "  pair = max(stats, key=stats.get)\n",
        "  idx = 256 + i\n",
        "#   print(f\"merging {pair} into a new token {idx}\")\n",
        "  ids = merge(ids, pair, idx)\n",
        "  merges[pair] = idx\n",
        "  if stats[pair] <= 2:\n",
        "    break\n",
        "\n",
        "print(f\"vocab size: {len(set(ids))}\")\n",
        "print(f\"Number of merges: {i}\")\n",
        "print(f\"Number of occurences of last merged tokens: {stats[pair]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0YR_heS6QGp",
        "outputId": "88f83f94-c30b-4c51-f151-749f67bed0c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab size: 986\n",
            "Number of merges: 926\n",
            "Number of occurences of last merged tokens: 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"tokens length:\", len(tokens))\n",
        "print(\"ids length:\", len(ids))\n",
        "print(f\"compression ratio: {len(tokens) / len(ids):.2f}X\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGydEwJI7B7l",
        "outputId": "24801f1f-64c9-497a-9d7f-6cb65d1f9736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokens length: 443302\n",
            "ids length: 55212\n",
            "compression ratio: 8.03X\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decode"
      ],
      "metadata": {
        "id": "tBA3-tOGr2jA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {idx: bytes([idx]) for idx in range(256)}\n",
        "for (p0, p1), idx in merges.items():\n",
        "    vocab[idx] = vocab[p0] + vocab[p1]\n",
        "\n",
        "def decode(ids):\n",
        "  # given ids (list of integers), return Python string\n",
        "  tokens = b\"\".join(vocab[idx] for idx in ids)\n",
        "  text = tokens.decode(\"utf-8\", errors=\"replace\")\n",
        "  return text\n",
        "\n",
        "print(decode([325]))"
      ],
      "metadata": {
        "id": "lBlgbulo_AdH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad85f92b-182f-4628-e002-32d4198226bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "স\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode([1181])), max(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP6fzLdYsuwW",
        "outputId": "1725f4e7-5710-474f-fdd5-c1300eaca981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "�পনাদের �\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 1182)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encode"
      ],
      "metadata": {
        "id": "V4F_u4q6r4nf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(text):\n",
        "  # given a string, return list of integers (the tokens)\n",
        "  tokens = list(text.encode(\"utf-8\"))\n",
        "  while len(tokens) >= 2:\n",
        "    stats = get_stats(tokens)\n",
        "    pair = min(stats, key=lambda p: merges.get(p, float(\"inf\")))\n",
        "    if pair not in merges:\n",
        "      break # nothing else can be merged\n",
        "    idx = merges[pair]\n",
        "    tokens = merge(tokens, pair, idx)\n",
        "  return tokens\n",
        "\n",
        "print(encode(\"স\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjVLDbRJrejP",
        "outputId": "234fe434-4aff-4826-e4d6-a42d4229a5b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[325]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(encode(\"য\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VUNCA7wuIdo",
        "outputId": "2c4a1fd1-d301-47e7-fcc7-bc4a3487e7fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[256, 175]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Test whether encoding and then decoding of training text results into same text\n",
        "text2 = decode(encode(ben_text))\n",
        "print(text2 == ben_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ml6-PC8rpiy",
        "outputId": "7b3409ab-89a7-4e21-ba62-7094804f9c8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valtext = \"Many common characters, including numerals, punctuation, and other symbols, are unified within the standard and are not treated as specific to any given writing system. Unicode encodes thousands of emoji, with the continued development thereof conducted by the Consortium as a part of the standard.[4] Moreover, the widespread adoption of Unicode was in large part responsible for the initial popularization of emoji outside of Japan. Unicode is ultimately capable of encoding more than 1.1 million characters.\"\n",
        "valtext2 = decode(encode(valtext))\n",
        "print(valtext2 == valtext)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAOHzNnvsDIi",
        "outputId": "28910eb6-3395-4450-e479-7fd948af039f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o72OzxT9sbxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FT3vpeELOhvn"
      },
      "source": [
        "### Forced splits using regex patterns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJRbaD7gOhvn",
        "outputId": "6c603fc1-dcbc-4b42-ea4c-432783e26d27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['সবাই', ' যা', ' করতে', ' চায়', ' তা', ' করতে', ' চায়নি', '।', '\\n', 'একা', ' থাকার', ' একটা', ' অসুবিধে', ' হোলো', ' যে', ' কথা', ' বলার', ' মতো', ' কেউ', ' থাকে', ' না', '।', '\\n', 'আপনার', ' সমস্ত', ' অর্থ', ' দিয়ে', ' আপনি', ' যা', ' চান', ' তা', ' কিনতে', ' সক্ষম', ' হওয়া', ' উচিত', '।', '\\n', 'বাইরে', ' এতই', ' গরম', ' যে', ' আমি', ' পুরোদিন', ' আমার', ' শীততাপ', ' নিয়ন্ত্রিত', ' বাড়িতে', ' থাকতে', ' চাই', '।', '\\n', 'সকালে', ' সূর্য', ' পূর্ব', ' দিকে', ' ওঠে', ' এবং', ' সন্ধ্যায়', ' পশ্চিমে', ' অস্ত', ' যায়', '।', '\\n', 'আমি', ' শুনলাম', ' যে', ' তাঁরা', ' পার্ক', ' স্ট্রিটের', ' একটা', ' বাড়ির', ' ভিতের', ' মধ্যে', ' থেকে', ' একটা', ' কঙ্কাল', ' পেয়েছেন', '।', '\\n', 'টম', ' যখন', ' শুনলো', ' যে', ' মেরি', ' আরে', ' জন', ' বিয়ে', ' করেছে', ' তখন', ' তাকে', ' দেখে', ' বেশ', ' অবাক', ' মনে', ' হয়েছিলো', '।', '\\n', 'আমার', ' মনে', ' হয়', ' টম', ' যে', ' সোনা', ' পেয়েছে', ' সেটা', ' তার', ' কাছে', ' রাখতে', ' দেওয়া', ' হবে', ' এমন', ' সম্ভাবনা', ' খুব', ' কম', '।', '\\n', 'টম', ' মেরিকে', ' বললো', ' যে', ' ও', ' নিজেকে', ' হত্যা', ' করতে', ' চলেছিলো', ',', ' কিন্ত', ' তা', ' করার', ' মতো', ' সাহস', ' ছিলো', ' না', '।', '\\n', 'টমের', ' সঙ্গে', ' কাজ', ' করা', ' খুব', ' বিরক্তিকর', ' কারণ', ' ও', ' কখনই', ' মেনে', ' নেয়', ' না', ' যে', ' ও', ' ভুল', ' করেছে', '।', '\\n', 'আমি', ' ভেবেছিলাম', ' এটা', ' করা', ' সহজ', ' হবে', ',', ' কিন্তু', ' আমরা', ' সারাদিন', ' ধরে', ' কাজ', ' করেছি', ' আর', ' এখনো', ' শেষ', ' করে', ' উঠতে', ' পারিনি', '।', '\\n', 'আমি', ' ভেবেছিলাম', ' এটা', ' করা', ' সহজ', ' হবে', ',', ' কিন্তু', ' আমরা', ' সারাদিন', ' ধরে', ' কাজ', ' করেছি', ' আর', ' এখনো', ' শেষ', ' করে', ' উঠতে', ' পারিনি', '।', '\\n', 'বছরের', ' বারোটা', ' মাস', ' হলো', ' জানুয়ারি', ',', ' ফেব্রুয়ারি', ',', ' মার্চ', ',', ' এপ্রিল', ',', ' মে', ',', ' জুন', ' জুলাই', ',', ' আগস্ট', ',', ' সেপ্টেম্বর', ',', ' অক্টোবর', ',', ' নভেম্বর', ' আর', ' ডিসেম্বর', '।']\n"
          ]
        }
      ],
      "source": [
        "import regex as re\n",
        "# gpt2pat = re.compile(r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\")\n",
        "# https://www.regular-expressions.info/refext.html\n",
        "# https://stackoverflow.com/questions/70985982/how-to-check-if-a-python-string-is-a-valid-bengali-word-using-regular-expression\n",
        "ben_pat = re.compile(r\"\"\" ?\\p{Bengali}+| ?[^\\s\\p{Bengali}]+|\\s+(?!\\S)|\\s+\"\"\")\n",
        "\n",
        "print(re.findall(ben_pat, \"\"\"সবাই যা করতে চায় তা করতে চায়নি।\n",
        "একা থাকার একটা অসুবিধে হোলো যে কথা বলার মতো কেউ থাকে না।\n",
        "আপনার সমস্ত অর্থ দিয়ে আপনি যা চান তা কিনতে সক্ষম হওয়া উচিত।\n",
        "বাইরে এতই গরম যে আমি পুরোদিন আমার শীততাপ নিয়ন্ত্রিত বাড়িতে থাকতে চাই।\n",
        "সকালে সূর্য পূর্ব দিকে ওঠে এবং সন্ধ্যায় পশ্চিমে অস্ত যায়।\n",
        "আমি শুনলাম যে তাঁরা পার্ক স্ট্রিটের একটা বাড়ির ভিতের মধ্যে থেকে একটা কঙ্কাল পেয়েছেন।\n",
        "টম যখন শুনলো যে মেরি আরে জন বিয়ে করেছে তখন তাকে দেখে বেশ অবাক মনে হয়েছিলো।\n",
        "আমার মনে হয় টম যে সোনা পেয়েছে সেটা তার কাছে রাখতে দেওয়া হবে এমন সম্ভাবনা খুব কম।\n",
        "টম মেরিকে বললো যে ও নিজেকে হত্যা করতে চলেছিলো, কিন্ত তা করার মতো সাহস ছিলো না।\n",
        "টমের সঙ্গে কাজ করা খুব বিরক্তিকর কারণ ও কখনই মেনে নেয় না যে ও ভুল করেছে।\n",
        "আমি ভেবেছিলাম এটা করা সহজ হবে, কিন্তু আমরা সারাদিন ধরে কাজ করেছি আর এখনো শেষ করে উঠতে পারিনি।\n",
        "আমি ভেবেছিলাম এটা করা সহজ হবে, কিন্তু আমরা সারাদিন ধরে কাজ করেছি আর এখনো শেষ করে উঠতে পারিনি।\n",
        "বছরের বারোটা মাস হলো জানুয়ারি, ফেব্রুয়ারি, মার্চ, এপ্রিল, মে, জুন জুলাই, আগস্ট, সেপ্টেম্বর, অক্টোবর, নভেম্বর আর ডিসেম্বর।\"\"\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bengali tokenizer with regex"
      ],
      "metadata": {
        "id": "g1L32CLMYu2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import regex as re"
      ],
      "metadata": {
        "id": "FDqbilxHUBGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 5001 # the desired final vocabulary size\n",
        "num_merges = vocab_size - 256"
      ],
      "metadata": {
        "id": "qOe4_SKLaK9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# regex pattern for bengali text\n",
        "regex_pat = re.compile(r\"\"\" ?\\p{Bengali}+| ?[^\\s\\p{Bengali}]+|\\s+(?!\\S)|\\s+\"\"\")"
      ],
      "metadata": {
        "id": "Vj_6fnLdYuFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the text up into text chunks\n",
        "text_chunks = re.findall(regex_pat, ben_text)"
      ],
      "metadata": {
        "id": "DeAv6CVZvnEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input text preprocessing\n",
        "ids = [list(ch.encode(\"utf-8\")) for ch in text_chunks]"
      ],
      "metadata": {
        "id": "RDZ9hDSOZMls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_stats(ids, counts= None):\n",
        "    counts = {} if counts is None else counts\n",
        "    for pair in zip(ids, ids[1:]):\n",
        "        counts[pair] = counts.get(pair, 0) + 1\n",
        "    return counts\n",
        "\n",
        "def merge(ids, pair, idx):\n",
        "    newids = []\n",
        "    i = 0\n",
        "    while i < len(ids):\n",
        "        if i < len(ids) - 1 and ids[i] == pair[0] and ids[i+1] == pair[1]:\n",
        "            newids.append(idx)\n",
        "            i += 2\n",
        "        else:\n",
        "            newids.append(ids[i])\n",
        "            i += 1\n",
        "    return newids"
      ],
      "metadata": {
        "id": "b566PP3tZfE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# iteratively merge the most common pairs to create new tokens\n",
        "merges = {} # (int, int) -> int\n",
        "vocab = {idx: bytes([idx]) for idx in range(256)} # idx -> bytes\n",
        "for i in range(num_merges):\n",
        "    # count the number of times every consecutive pair appears\n",
        "    stats = {}\n",
        "    for chunk_ids in ids:\n",
        "        # passing in stats will update it in place, adding up counts\n",
        "        get_stats(chunk_ids, stats)\n",
        "    # find the pair with the highest count\n",
        "    pair = max(stats, key=stats.get)\n",
        "    if stats[pair] < 2: # there should be at least 2 occurances\n",
        "        print(\"exitting - less than 2 occurances\")\n",
        "        break\n",
        "    # mint a new token: assign it the next available id\n",
        "    idx = 256 + i\n",
        "    # replace all occurrences of pair in ids with idx\n",
        "    ids = [merge(chunk_ids, pair, idx) for chunk_ids in ids]\n",
        "    # save the merge\n",
        "    merges[pair] = idx\n",
        "    vocab[idx] = vocab[pair[0]] + vocab[pair[1]]\n",
        "\n",
        "\n",
        "print(f\"vocab size: {len(vocab)}\")\n",
        "print(f\"Number of merges: {i}\")\n",
        "print(f\"Number of occurences of last merged tokens: {stats[pair]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyUJs-nwZRAr",
        "outputId": "dd60500b-5071-4714-cfbd-44e2418514af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "exitting - less than 2 occurances\n",
            "vocab size: 4734\n",
            "Number of merges: 4478\n",
            "Number of occurences of last merged tokens: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pair"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKomhPj9aK3k",
        "outputId": "22903038-aa09-4f31-a576-089c6e2e0693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2855, 396)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"tokens length:\", len(tokens))\n",
        "print(\"ids length:\", len(ids))\n",
        "print(f\"compression ratio: {len(tokens) / len(ids):.2f}X\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f235EeL6auiO",
        "outputId": "96a3cfbc-9d63-46ee-d4c0-97561f7fe44a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokens length: 443302\n",
            "ids length: 43603\n",
            "compression ratio: 10.17X\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decode"
      ],
      "metadata": {
        "id": "9SQIbi1Vbeec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(ids):\n",
        "    # given ids (list of integers), return Python string\n",
        "    part_bytes = []\n",
        "    for idx in ids:\n",
        "        if idx in vocab:\n",
        "            part_bytes.append(vocab[idx])\n",
        "        else:\n",
        "            raise ValueError(f\"invalid token id: {idx}\")\n",
        "    text_bytes = b\"\".join(part_bytes)\n",
        "    text = text_bytes.decode(\"utf-8\", errors=\"replace\")\n",
        "    return text\n",
        "\n",
        "print(decode([325]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc34df5f-3aec-4033-8416-ba91e9f1c59b",
        "id": "6vf8V6edbeed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "াল\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode([2855])), print(decode([396]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOwU6VrpaQJa",
        "outputId": "0b46ff66-3e97-4bad-f05e-ff46662eba5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "পাল\n",
            "াও\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode([999]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77c27a6f-f8e7-41a6-d506-33095d5122d1",
        "id": "z70uBU3ebeed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "আজ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encode"
      ],
      "metadata": {
        "id": "ZYV9BSpcbeed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _encode_chunk(text_bytes):\n",
        "        # return the token ids\n",
        "        # let's begin. first, convert all bytes to integers in range 0..255\n",
        "        ids = list(text_bytes)\n",
        "        while len(ids) >= 2:\n",
        "            # find the pair with the lowest merge index\n",
        "            stats = get_stats(ids)\n",
        "            pair = min(stats, key=lambda p: merges.get(p, float(\"inf\")))\n",
        "            # subtle: if there are no more merges available, the key will\n",
        "            # result in an inf for every single pair, and the min will be\n",
        "            # just the first pair in the list, arbitrarily\n",
        "            # we can detect this terminating case by a membership check\n",
        "            if pair not in merges:\n",
        "                break # nothing else can be merged anymore\n",
        "            # otherwise let's merge the best pair (lowest merge index)\n",
        "            idx = merges[pair]\n",
        "            ids = merge(ids, pair, idx)\n",
        "        return ids\n",
        "\n",
        "def encode(text):\n",
        "    # split text into chunks of text by categories defined in regex pattern\n",
        "    text_chunks = re.findall(regex_pat, text)\n",
        "    # all chunks of text are encoded separately, then results are joined\n",
        "    ids = []\n",
        "    for chunk in text_chunks:\n",
        "        chunk_bytes = chunk.encode(\"utf-8\") # raw bytes\n",
        "        chunk_ids = _encode_chunk(chunk_bytes)\n",
        "        ids.extend(chunk_ids)\n",
        "    return ids\n",
        "\n",
        "\n",
        "print(encode(\"স\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac3ed11f-7f9c-4d2b-e35b-07730ba7ec6c",
        "id": "u5QQusnVbeed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[295]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(encode(\"বিরক্তিকর\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a78c334-6b1e-4049-a126-7e4563292082",
        "id": "XTA0poZUbeed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[285, 453, 790, 2697]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print([decode([i]) for i in encode(\"বিরক্তিকর\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmYfMmc3eq-_",
        "outputId": "4d2e0433-0e68-4a45-cc51-962a2f873173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ব', 'ির', 'ক্ত', 'িকর']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Test whether encoding and then decoding of training text results into same text\n",
        "text2 = decode(encode(ben_text))\n",
        "print(text2 == ben_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32f04c77-e966-4b78-a9ee-a26f59754659",
        "id": "SSAv2iKPbeed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valtext = \"\"\"\n",
        "বিশেষভাবে হত্যাকা-ের শিকার হচ্ছে শিশুরা।\n",
        "অন্যদের কোনওরকমভাবে হয়রান করা হচ্ছে না।\n",
        "বিক্ষোভকারীদের ওপর পুলিশ কাঁদানে গ্যাস ছোড়ে।\n",
        "সেটা ফেরত পাওয়া খুব সোজা ব্যাপার নয়, অনিমেষ।\n",
        "পরে হাসপাতাল থেকেও তাঁকে বের করে দেওয়া হয়।\n",
        "নয়তো কার?\n",
        "সম্প্রতি শারীরিক অসুস্থতার কারণে তাঁকে ভর্তি করা হয় সেখানকার হাসপাতালে।\n",
        "ইতিমধ্যে ছবির শুটিংও শুরু হয়ে গেছে মুম্বইয়ের ধারাবি অঞ্চলে।\n",
        "\"\"\"\n",
        "valtext2 = decode(encode(valtext))\n",
        "print(valtext2 == valtext)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8fba6ce-0aef-4791-a9f2-0c672a63be59",
        "id": "zKPTryD2beed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R3h2jPvcjNhD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}